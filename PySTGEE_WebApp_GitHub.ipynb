{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpOsg-GUOk9G"
      },
      "outputs": [],
      "source": [
        "# ***************************************************************************\n",
        "#    PySTGEE: Python Implementation for Spatio-Temporal GEE Landslide Modeling\n",
        "#\n",
        "#        Original Project     : STGEE (JavaScript/GEE)\n",
        "#        Original Begin       : 2022-04\n",
        "#        Original Copyright   : (C) 2022 by Giacomo Titti and Gabriele Nicola Napoli\n",
        "#        Original Contact     : giacomotitti@gmail.com\n",
        "#\n",
        "#        Python Refactoring   : 2025-11\n",
        "#        Updated Copyright    : (C) 2025 by Gabriele Nicola Napoli and Giacomo Titti\n",
        "#        Contacts             : gabrielenicolanapoli@gmail.com, giacomotitti@gmail.com\n",
        "#\n",
        "# ***************************************************************************\n",
        "# ***************************************************************************\n",
        "#    PySTGEE\n",
        "#    Copyright (C) 2022 Giacomo Titti, Gabriele Nicola Napoli\n",
        "#    Copyright (C) 2025 Gabriele Nicola Napoli, Giacomo Titti\n",
        "#\n",
        "#    This program is free software: you can redistribute it and/or modify\n",
        "#    it under the terms of the GNU General Public License as published by\n",
        "#    the Free Software Foundation, either version 3 of the License, or\n",
        "#    (at your option) any later version.\n",
        "#\n",
        "#    This program is distributed in the hope that it will be useful,\n",
        "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "#    GNU General Public License for more details.\n",
        "#\n",
        "#    You should have received a copy of the GNU General Public License\n",
        "#    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
        "# ***************************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igg3A-gCPmTi",
        "outputId": "9d14ff37-7ab2-4cc1-a851-9b091a8bf298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration Saved.\n",
            "Project: stgee-dataset\n",
            "CSV Mode: BEST_ONLY\n",
            "Rainfall Optimization Range: 1 to 30 days.\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# --- CELL 1: USER CONFIGURATION ---\n",
        "\n",
        "# 1. Earth Engine Project Configuration\n",
        "EE_PROJECT = 'your-ee-project-id'  # Enter your GEE Project ID here\n",
        "\n",
        "# 2. Earth Engine Asset Paths\n",
        "# Polygons used for training (Slope Units)\n",
        "polygons_asset = \"projects/ee-your-username/assets/your_training_polygons\"\n",
        "# Point data containing landslide events and dates\n",
        "points_asset = \"projects/ee-your-username/assets/your_landslide_points\"\n",
        "# Polygons used for final prediction/forecasting\n",
        "prediction_asset = \"projects/ee-your-username/assets/your_prediction_polygons\"\n",
        "\n",
        "# 3. Data Column Settings\n",
        "# The exact name of the column in 'points_asset' that contains the date\n",
        "DATE_COLUMN = 'date_column_name'\n",
        "\n",
        "# The exact name of the column identifying the landslide (e.g. 'id', 'objectid', 'type')\n",
        "LANDSLIDE_COLUMN = 'landslide_id'\n",
        "\n",
        "# 4. CSV Export Settings\n",
        "# 'BEST_ONLY': CSV contains only the best rainfall column (Max AUC) + static predictors.\n",
        "# 'ALL_DATA' : CSV contains ALL calculated rainfall columns (1-30 days).\n",
        "CSV_EXPORT_MODE = 'BEST_ONLY'\n",
        "\n",
        "# 5. Analysis Parameters\n",
        "# The specific date to generate the final hazard map for\n",
        "FORECAST_DATE_FIXED = 'YYYY-MM-DD'\n",
        "\n",
        "# Static Morphological Predictors Examples (Rainfall will be added dynamically)\n",
        "STATIC_PREDICTORS = [\n",
        "    'slope_mean',          # Mean slope\n",
        "    'elevation_mean',      # Mean elevation\n",
        "    'curvature_mean',      # Terrain curvature\n",
        "    'ndvi_mean',           # Vegetation index\n",
        "    'lithology_class'      # Categorical lithology\n",
        "]\n",
        "\n",
        "\n",
        "# Rainfall Window Search Range (Days)\n",
        "# The model will test every interval between MIN and MAX to find the best AUC\n",
        "MIN_DAYS = 1\n",
        "MAX_DAYS = 30\n",
        "\n",
        "print(f\"Configuration Saved.\")\n",
        "print(f\"Project: {EE_PROJECT}\")\n",
        "print(f\"CSV Mode: {CSV_EXPORT_MODE}\")\n",
        "print(f\"Rainfall Optimization Range: {MIN_DAYS} to {MAX_DAYS} days.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "glwpRyNHQG2a"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# --- CELL 2: IMPORTS AND SYSTEM SETUP ---\n",
        "import ee\n",
        "import geemap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "import re\n",
        "import concurrent.futures\n",
        "import os\n",
        "import json\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Machine Learning Imports\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, cohen_kappa_score, accuracy_score\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Earth Engine Initialization\n",
        "# This block automatically detects if it's running as a WebApp (via Service Account)\n",
        "# or in a standard environment (Colab/Local).\n",
        "try:\n",
        "    # 1. WEBAPP MODE: Check for Service Account credentials in environment variables\n",
        "    if 'EE_SERVICE_ACC_JSON' in os.environ:\n",
        "        print(\"Authenticating via Service Account for WebApp deployment...\")\n",
        "        # Parse the JSON credentials stored in the environment variable\n",
        "        creds_json = os.environ['EE_SERVICE_ACC_JSON']\n",
        "        creds_dict = json.loads(creds_json)\n",
        "\n",
        "        # Initialize using Service Account Credentials\n",
        "        credentials = ee.ServiceAccountCredentials(\n",
        "            creds_dict['client_email'],\n",
        "            key_data=creds_json\n",
        "        )\n",
        "        ee.Initialize(credentials, project=EE_PROJECT)\n",
        "        print(f\"Connected to Earth Engine via Service Account (Project: {EE_PROJECT}).\")\n",
        "\n",
        "    else:\n",
        "        # 2. STANDARD MODE: Local or Google Colab environment\n",
        "        try:\n",
        "            # Attempt direct initialization (works if already authenticated)\n",
        "            ee.Initialize(project=EE_PROJECT)\n",
        "            print(f\"Connected to Earth Engine (Project: {EE_PROJECT}).\")\n",
        "        except Exception:\n",
        "            # Fallback to interactive authentication if needed\n",
        "            print(\"Standard initialization failed. Attempting interactive authentication...\")\n",
        "            ee.Authenticate()\n",
        "            ee.Initialize(project=EE_PROJECT)\n",
        "            print(f\"Authentication completed (Project: {EE_PROJECT}).\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"CRITICAL ERROR: Failed to initialize Earth Engine: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vr1_6Dd5WSyg"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# --- CELL 3: DATA LOADING & PRE-PROCESSING ---\n",
        "\n",
        "# Visualization Palettes (Static)\n",
        "VIS_PALETTE = [\n",
        "    '#006b0b', '#1b7b25', '#4e9956', '#dbeadd', '#ffffff',\n",
        "    '#f0b2ae', '#eb958f', '#df564d', '#d10e00'\n",
        "]\n",
        "PALETTE_CONFUSION = ['#D10E00', '#DF564D', '#DBEADD', '#006B0B']\n",
        "\n",
        "# Load Collections using variables from CELL 1\n",
        "print(f\"Loading assets...\")\n",
        "raw_polygons = ee.FeatureCollection(polygons_asset)\n",
        "landPoints = ee.FeatureCollection(points_asset)\n",
        "raw_prediction = ee.FeatureCollection(prediction_asset)\n",
        "\n",
        "# Function to extract numeric IDs from polygon attributes (essential for mapping)\n",
        "def add_numeric_id(feature):\n",
        "    str_id = ee.String(feature.get('id'))\n",
        "    # Remove non-numeric characters\n",
        "    num_str = str_id.replace(r'[^0-9]', '', 'g')\n",
        "    # Parse to number, default to 0 if empty\n",
        "    num_val = ee.Algorithms.If(num_str.length().gt(0), ee.Number.parse(num_str), 0)\n",
        "    return feature.set('NUM_ID', num_val)\n",
        "\n",
        "# Apply ID extraction\n",
        "predictors_polygons = raw_polygons.map(add_numeric_id)\n",
        "prediction_area_shp = raw_prediction.map(add_numeric_id)\n",
        "\n",
        "# Global App State to store data between button clicks\n",
        "APP = {\n",
        "    'df': None,            # The training dataframe\n",
        "    'model': None,         # The trained Random Forest model\n",
        "    'map': None,           # The map widget\n",
        "    'best_window': None,   # The optimized rainfall window (e.g., 12 days)\n",
        "    'final_predictors': [] # The final list of columns used (Static + Best Rain)\n",
        "}\n",
        "\n",
        "print(\"Assets configured and ready for analysis.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nR8ODbD6Ww_p"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# --- CELL 4: TRAINING ENGINE (DETERMINISTIC & OPTIMIZED) ---\n",
        "\n",
        "def download_training_data_server_side(log_widget):\n",
        "    \"\"\"\n",
        "    Downloads training data for all days between MIN_DAYS and MAX_DAYS.\n",
        "    Includes SORTING to ensure deterministic results across runs.\n",
        "    Uses 'DATE_COLUMN' from configuration to identify dates.\n",
        "    \"\"\"\n",
        "    # Use the dynamic column name defined in Cell 1\n",
        "    raw_dates = landPoints.aggregate_array(DATE_COLUMN).distinct().getInfo()\n",
        "    dates_list = [str(d)[:10] for d in raw_dates]\n",
        "\n",
        "    with log_widget:\n",
        "        print(f\"Event Dates found: {len(dates_list)}\")\n",
        "        print(f\"Retrieving rainfall data for windows {MIN_DAYS}-{MAX_DAYS} days...\")\n",
        "\n",
        "    def process_date(date_str):\n",
        "        try:\n",
        "            d = ee.Date(date_str)\n",
        "            gpm = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v8/operational').select('hourlyPrecipRateGC')\n",
        "\n",
        "            # OPTIMIZATION: List Comprehension\n",
        "            rain_bands = [\n",
        "                gpm.filterDate(d.advance(-i, 'day'), d).sum().unmask(0).rename(f'Rn{i}')\n",
        "                for i in range(MIN_DAYS, MAX_DAYS + 1)\n",
        "            ]\n",
        "\n",
        "            combined = ee.Image.cat(rain_bands)\n",
        "\n",
        "            # Filter points using the dynamic date column\n",
        "            todays_points = landPoints.filter(ee.Filter.eq(DATE_COLUMN, date_str))\n",
        "\n",
        "            def map_polygons(poly):\n",
        "                count = todays_points.filterBounds(poly.geometry()).size()\n",
        "                # We retain 'system:index' (id) for sorting later\n",
        "                return poly.set({'P/A': ee.Algorithms.If(count.gt(0), 1, 0), 'date': date_str})\n",
        "\n",
        "            labeled_polys = predictors_polygons.map(map_polygons)\n",
        "\n",
        "            stats = combined.reduceRegions(\n",
        "                collection=labeled_polys,\n",
        "                reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), sharedInputs=True),\n",
        "                scale=1000, tileScale=16\n",
        "            )\n",
        "\n",
        "            df_day = geemap.ee_to_df(stats)\n",
        "            if df_day.empty: return None\n",
        "\n",
        "            rename_dict = {f'Rn{i}_{suffix}': f'Rn{i}_{m}'\n",
        "                           for i in range(MIN_DAYS, MAX_DAYS + 1)\n",
        "                           for suffix, m in [('mean', 'm'), ('stdDev', 's')]}\n",
        "\n",
        "            df_day = df_day.rename(columns=rename_dict)\n",
        "            return df_day\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    results = []\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        futures = [executor.submit(process_date, d) for d in dates_list]\n",
        "        for i, f in enumerate(concurrent.futures.as_completed(futures)):\n",
        "            res = f.result()\n",
        "            if res is not None: results.append(res)\n",
        "            if i % 5 == 0:\n",
        "                with log_widget: print(f\"   ...processed {i}/{len(dates_list)} dates\", end='\\r')\n",
        "\n",
        "    if not results: return pd.DataFrame()\n",
        "\n",
        "    final_df = pd.concat(results, ignore_index=True)\n",
        "\n",
        "    # --- FIX: DETERMINISTIC SORTING ---\n",
        "    # Sort by Date and then by ID to ensure rows are ALWAYS in the exact same order\n",
        "    if 'date' in final_df.columns and 'id' in final_df.columns:\n",
        "        final_df = final_df.sort_values(by=['date', 'id']).reset_index(drop=True)\n",
        "\n",
        "    # Ensure static predictors exist\n",
        "    for col in STATIC_PREDICTORS:\n",
        "        if col not in final_df.columns: final_df[col] = 0\n",
        "\n",
        "    return final_df.fillna(0)\n",
        "\n",
        "print(\"Training Engine ready (Dynamic Date Column).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VmkafQE6cVNS"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# --- CELL 5: PREDICTION ENGINE ---\n",
        "\n",
        "def get_prediction_data_dynamic(best_days_n, log_widget=None):\n",
        "    \"\"\"\n",
        "    Downloads rainfall data for the winning window.\n",
        "    SMART FEATURE: If data for FORECAST_DATE_FIXED is missing (latency),\n",
        "    it automatically finds and uses the MOST RECENT available date in the dataset.\n",
        "\n",
        "    Args:\n",
        "        best_days_n (int): Number of days for rainfall accumulation.\n",
        "        log_widget (Output): The widget to print logs to (optional).\n",
        "    \"\"\"\n",
        "\n",
        "    # Helper to print to the specific widget or standard console\n",
        "    def log(msg):\n",
        "        if log_widget:\n",
        "            with log_widget: print(msg)\n",
        "        else:\n",
        "            print(msg)\n",
        "\n",
        "    target_date = ee.Date(FORECAST_DATE_FIXED)\n",
        "\n",
        "    # 1. Use JAXA GSMaP Collection\n",
        "    gpm = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v8/operational').select('hourlyPrecipRateGC')\n",
        "\n",
        "    # --- \"FIND MOST RECENT DATE\" LOGIC ---\n",
        "    # Search for all available images BEFORE or EQUAL to the target date.\n",
        "    available_col = gpm.filterDate('2000-01-01', target_date.advance(1, 'day')) \\\n",
        "                       .sort('system:time_start', False) \\\n",
        "                       .limit(1)\n",
        "\n",
        "    # Check if at least one image exists in the history\n",
        "    has_data = available_col.size().getInfo() > 0\n",
        "\n",
        "    found_date_str = \"N/A\"\n",
        "\n",
        "    log(\"-\" * 45)\n",
        "    log(\"      SATELLITE DATA REPORT\")\n",
        "    log(\"-\" * 45)\n",
        "    log(f\"Requested Date : {FORECAST_DATE_FIXED}\")\n",
        "\n",
        "    if has_data:\n",
        "        # Get the most recent image found\n",
        "        latest_img = available_col.first()\n",
        "\n",
        "        # Retrieve the date of this image\n",
        "        found_date_ms = latest_img.get('system:time_start').getInfo()\n",
        "        found_date = ee.Date(found_date_ms)\n",
        "        found_date_str = found_date.format('YYYY-MM-dd').getInfo()\n",
        "\n",
        "        log(f\"Source Image   : JAXA GSMaP v8 Operational\")\n",
        "        log(f\"Available Date : {found_date_str}\")\n",
        "\n",
        "        # If the found date is different from the requested one\n",
        "        if found_date_str != FORECAST_DATE_FIXED:\n",
        "            diff = ee.Date(FORECAST_DATE_FIXED).difference(found_date, 'day').getInfo()\n",
        "            log(f\"STATUS         : FALLBACK ACTIVATED\")\n",
        "            log(f\"   (Data lag of {int(diff)} days due to latency/missing data)\")\n",
        "            log(f\"   Using rainfall accumulation ending on {found_date_str}\")\n",
        "        else:\n",
        "            log(f\"STATUS         : EXACT MATCH\")\n",
        "\n",
        "        log(\"-\" * 45)\n",
        "\n",
        "        # --- RAINFALL CALCULATION ---\n",
        "        rain_img = gpm.filterDate(found_date.advance(-best_days_n, 'day'), found_date.advance(1, 'day')) \\\n",
        "                      .sum().unmask(0).rename(f'Rn{best_days_n}')\n",
        "\n",
        "    else:\n",
        "        log(\"STATUS         : NO DATA FOUND (Using 0 Rain)\")\n",
        "        log(\"-\" * 45)\n",
        "        rain_img = ee.Image.constant(0).rename(f'Rn{best_days_n}')\n",
        "\n",
        "    # --- REDUCE REGIONS ---\n",
        "    stats = rain_img.reduceRegions(\n",
        "        collection=prediction_area_shp,\n",
        "        reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), sharedInputs=True),\n",
        "        scale=1000, tileScale=16\n",
        "    )\n",
        "\n",
        "    df = geemap.ee_to_df(stats)\n",
        "\n",
        "    # --- ROBUST RENAMING ---\n",
        "    target_mean = f'Rn{best_days_n}_m'\n",
        "    target_std = f'Rn{best_days_n}_s'\n",
        "\n",
        "    possible_means = [f'Rn{best_days_n}_mean', 'hourlyPrecipRateGC_mean', 'mean']\n",
        "    possible_stds = [f'Rn{best_days_n}_stdDev', 'hourlyPrecipRateGC_stdDev', 'stdDev']\n",
        "\n",
        "    found_col = False\n",
        "    for col in possible_means:\n",
        "        if col in df.columns:\n",
        "            df[target_mean] = df[col]\n",
        "            found_col = True\n",
        "            break\n",
        "    if not found_col: df[target_mean] = 0\n",
        "\n",
        "    found_col = False\n",
        "    for col in possible_stds:\n",
        "        if col in df.columns:\n",
        "            df[target_std] = df[col]\n",
        "            found_col = True\n",
        "            break\n",
        "    if not found_col: df[target_std] = 0\n",
        "\n",
        "    for col in STATIC_PREDICTORS:\n",
        "        if col not in df.columns: df[col] = 0\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\"Prediction Engine ready (Log Integration Enabled).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0ffO_Xug55m"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# --- CELL 6: DASHBOARD AND INTERFACE ---\n",
        "from ipyleaflet import WidgetControl, ZoomControl, FullScreenControl\n",
        "import base64\n",
        "import ipywidgets as widgets\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "def calc_confusion_class(row, pred_col, true_col='P/A'):\n",
        "    p = int(row[pred_col])\n",
        "    t = int(row[true_col])\n",
        "    if p == 1 and t == 0: return 0 # FP\n",
        "    if p == 0 and t == 0: return 1 # TN\n",
        "    if p == 0 and t == 1: return 2 # FN\n",
        "    if p == 1 and t == 1: return 3 # TP\n",
        "    return 1\n",
        "\n",
        "def create_download_link(df, title=\"Download CSV\", filename=\"data.csv\"):\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode()).decode()\n",
        "    payload = f'data:text/csv;base64,{b64}'\n",
        "    html = f'<a download=\"{filename}\" href=\"{payload}\" target=\"_blank\"><button style=\"background-color: #00BFFF; color: #ffffff !important; padding: 6px 12px; border: none; border-radius: 4px; cursor: pointer; font-size: 12px; font-family: sans-serif; font-weight: bold;\">{title}</button></a>'\n",
        "    return widgets.HTML(html)\n",
        "\n",
        "def filter_dataframe_for_export(df):\n",
        "    \"\"\"\n",
        "    Filters the DataFrame based on the CSV_EXPORT_MODE setting in Cell 1.\n",
        "    If 'BEST_ONLY', keeps only identification cols, final predictors, and results.\n",
        "    \"\"\"\n",
        "    if CSV_EXPORT_MODE == 'ALL_DATA':\n",
        "        return df\n",
        "\n",
        "    # Mode is 'BEST_ONLY'\n",
        "    # Define base identification columns\n",
        "    cols_to_keep = ['id', 'date', 'P/A', 'NUM_ID']\n",
        "\n",
        "    # Add the predictors used in the final model (Static + Best Rain)\n",
        "    if 'final_predictors' in APP:\n",
        "        cols_to_keep.extend(APP['final_predictors'])\n",
        "\n",
        "    # Add Result columns (if they exist in the df)\n",
        "    result_cols = ['calib_prob', 'calib_pred', 'conf_class',\n",
        "                   'valid_prob', 'valid_pred', 'valid_conf',\n",
        "                   'SI', 'Prediction']\n",
        "\n",
        "    for rc in result_cols:\n",
        "        if rc in df.columns:\n",
        "            cols_to_keep.append(rc)\n",
        "\n",
        "    # Filter: keep only columns that actually exist in the dataframe\n",
        "    final_cols = [c for c in cols_to_keep if c in df.columns]\n",
        "\n",
        "    return df[final_cols]\n",
        "\n",
        "def map_values(df_res, val_col, layer_name, palette):\n",
        "    m = APP['map']\n",
        "    try:\n",
        "        layer = m.find_layer(layer_name)\n",
        "        if layer: m.remove_layer(layer)\n",
        "    except: pass\n",
        "\n",
        "    def clean_id_py(val):\n",
        "        s = str(val)\n",
        "        digits = re.sub(r'[^0-9]', '', s)\n",
        "        return int(digits) if digits else 0\n",
        "\n",
        "    df_map = df_res.copy()\n",
        "    df_map['NUM_ID_PY'] = df_map['id'].apply(clean_id_py)\n",
        "\n",
        "    if layer_name.startswith(\"Confusion\"):\n",
        "        df_flat = df_map.sort_values('date').drop_duplicates(subset='NUM_ID_PY', keep='last')\n",
        "        is_visible = False\n",
        "    else:\n",
        "        df_flat = df_map.groupby('NUM_ID_PY')[val_col].max().reset_index()\n",
        "        is_visible = True\n",
        "\n",
        "    id_list = df_flat['NUM_ID_PY'].tolist()\n",
        "    val_list = df_flat[val_col].tolist()\n",
        "\n",
        "    polygons_img = predictors_polygons.reduceToImage(properties=['NUM_ID'], reducer=ee.Reducer.first())\n",
        "    result_img = polygons_img.remap(id_list, val_list).rename('value')\n",
        "    result_img = result_img.updateMask(result_img.gte(0))\n",
        "\n",
        "    vis = {'palette': palette, 'min': 0, 'max': 3 if layer_name.startswith(\"Confusion\") else 1}\n",
        "    m.addLayer(result_img, vis, layer_name, shown=is_visible)\n",
        "\n",
        "def calculate_advanced_metrics(y_true, y_probs):\n",
        "    fpr, tpr, roc_thresh = roc_curve(y_true, y_probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    youden_scores = tpr - fpr\n",
        "    best_idx = np.argmax(youden_scores)\n",
        "    best_thresh = roc_thresh[best_idx]\n",
        "    y_pred_opt = (y_probs >= best_thresh).astype(int)\n",
        "    f1 = f1_score(y_true, y_pred_opt, zero_division=0)\n",
        "    kappa = cohen_kappa_score(y_true, y_pred_opt)\n",
        "    acc = accuracy_score(y_true, y_pred_opt)\n",
        "    return {\n",
        "        'auc': roc_auc, 'best_thresh': best_thresh,\n",
        "        'f1': f1, 'kappa': kappa, 'acc': acc, 'youden': youden_scores[best_idx],\n",
        "        'fpr': fpr, 'tpr': tpr, 'best_idx': best_idx, 'y_pred_opt': y_pred_opt\n",
        "    }\n",
        "\n",
        "# --- FLOATING PANEL LOGIC ---\n",
        "APP['panels'] = {'calib': None, 'valid': None, 'pred': None}\n",
        "\n",
        "def show_floating_panel(content_widget, title=\"Results\", panel_key='calib', width='400px'):\n",
        "    if APP['panels'][panel_key] is not None:\n",
        "        try: APP['map'].remove_control(APP['panels'][panel_key])\n",
        "        except: pass\n",
        "        APP['panels'][panel_key] = None\n",
        "\n",
        "    btn_expand = widgets.Button(\n",
        "        description=f\"{title}\",\n",
        "        style=widgets.ButtonStyle(button_color='#00BFFF', text_color='#ffffff', font_weight='bold'),\n",
        "        layout=widgets.Layout(width='auto', padding='5px')\n",
        "    )\n",
        "\n",
        "    btn_minimize = widgets.Button(icon='minus', layout=widgets.Layout(width='30px', height='30px'), style=widgets.ButtonStyle(button_color='transparent', text_color='#000000'))\n",
        "\n",
        "    header_title = widgets.HTML(f'<span style=\"font-weight: bold; color: black; font-family: sans-serif;\">{title}</span>')\n",
        "    header = widgets.HBox([header_title, btn_minimize], layout=widgets.Layout(justify_content='space-between', width='100%', align_items='center', border_bottom='1px solid #eee'))\n",
        "\n",
        "    expanded_content = widgets.VBox(\n",
        "        [header, content_widget],\n",
        "        layout=widgets.Layout(\n",
        "            width=width,\n",
        "            background_color='white',\n",
        "            padding='10px',\n",
        "            border_radius='8px',\n",
        "            border='2px solid black',\n",
        "            box_shadow='0 4px 10px rgba(0,0,0,0.2)',\n",
        "            max_height='600px',\n",
        "            overflow_y='auto'\n",
        "        )\n",
        "    )\n",
        "    main_container = widgets.VBox([expanded_content])\n",
        "\n",
        "    def toggle_view(b): main_container.children = [btn_expand] if main_container.children[0] == expanded_content else [expanded_content]\n",
        "    btn_minimize.on_click(toggle_view)\n",
        "    btn_expand.on_click(toggle_view)\n",
        "\n",
        "    control = WidgetControl(widget=main_container, position='bottomright')\n",
        "    APP['map'].add_control(control)\n",
        "    APP['panels'][panel_key] = control\n",
        "\n",
        "# --- LEGEND ---\n",
        "def create_legend_widget():\n",
        "    title1 = widgets.HTML(value='<div style=\"font-weight: bold; font-size: 12px; color: #000000 !important; font-family: sans-serif;\">Calibration/Validation/Prediction map</div>')\n",
        "    colors_css = \", \".join(VIS_PALETTE)\n",
        "    gradient_html = f\"\"\"\n",
        "    <div style=\"width: 100%; margin-top: 5px;\">\n",
        "        <div style=\"display: flex; justify-content: space-between; font-size: 11px; margin-bottom: 2px; color: #000000 !important; font-family: sans-serif;\">\n",
        "            <span>0</span><span>1</span>\n",
        "        </div>\n",
        "        <div style=\"height: 12px; width: 200px; background: linear-gradient(to right, {colors_css}); border: 1px solid #999;\"></div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    gradient_widget = widgets.HTML(gradient_html)\n",
        "    title2 = widgets.HTML(value='<div style=\"font-weight: bold; font-size: 12px; margin-top: 15px; color: #000000 !important; font-family: sans-serif;\">Confusion map</div>')\n",
        "    labels = [\"False Positive\", \"True Negative\", \"False Negative\", \"True Positive\"]\n",
        "    colors = PALETTE_CONFUSION\n",
        "    legend_items = []\n",
        "    for col, txt in zip(colors, labels):\n",
        "        item_html = f\"\"\"\n",
        "        <div style=\"display: flex; align-items: center; margin: 2px 0;\">\n",
        "            <div style=\"width: 15px; height: 15px; background-color: {col}; border: 1px solid #999; margin-right: 8px;\"></div>\n",
        "            <span style=\"font-size: 11px; color: #000000 !important; font-family: sans-serif;\">{txt}</span>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        legend_items.append(widgets.HTML(item_html))\n",
        "    legend_content = widgets.VBox(\n",
        "        [title1, gradient_widget, title2] + legend_items,\n",
        "        layout=widgets.Layout(width='250px', padding='10px', background_color='white', border='2px solid black', border_radius='4px')\n",
        "    )\n",
        "    return legend_content\n",
        "\n",
        "# --- BUTTON HANDLERS ---\n",
        "out_log = widgets.Output(layout={'border': '1px solid #ccc', 'height': '150px', 'overflow_y': 'scroll', 'padding': '10px', 'margin': '10px 0'})\n",
        "\n",
        "def on_calib_click(b):\n",
        "    out_log.clear_output()\n",
        "    if APP['df'] is None: APP['df'] = download_training_data_server_side(out_log)\n",
        "    df = APP['df']\n",
        "    if df.empty: return\n",
        "\n",
        "    y = df['P/A']\n",
        "    best_auc = 0\n",
        "    best_days = MIN_DAYS\n",
        "\n",
        "    with out_log:\n",
        "        print(f\"Starting Optimization: Scanning windows {MIN_DAYS}-{MAX_DAYS} days...\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    for days in range(MIN_DAYS, MAX_DAYS + 1):\n",
        "        current_rain = [f'Rn{days}_m', f'Rn{days}_s']\n",
        "        current_predictors = current_rain\n",
        "        if not all(col in df.columns for col in current_rain): continue\n",
        "        X_temp = df[current_predictors].fillna(0)\n",
        "        rf_temp = RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42, n_jobs=-1, class_weight='balanced')\n",
        "        rf_temp.fit(X_temp, y)\n",
        "        probs = rf_temp.predict_proba(X_temp)[:, 1]\n",
        "        fpr, tpr, _ = roc_curve(y, probs)\n",
        "        current_auc = auc(fpr, tpr)\n",
        "\n",
        "        with out_log: print(f\"   > Day {days}: AUC = {current_auc:.4f}\")\n",
        "\n",
        "        if current_auc > best_auc:\n",
        "            best_auc = current_auc\n",
        "            best_days = days\n",
        "\n",
        "    APP['best_window'] = best_days\n",
        "    APP['final_predictors'] = STATIC_PREDICTORS + [f'Rn{best_days}_m', f'Rn{best_days}_s']\n",
        "\n",
        "    with out_log:\n",
        "        print(\"-\" * 30)\n",
        "        print(f\"FINAL SELECTION:\")\n",
        "        print(f\"   Best Window: {best_days} Days\")\n",
        "        print(f\"   Max AUC:     {best_auc:.4f}\")\n",
        "        print(\"-\" * 30)\n",
        "        print(\"Training final robust model...\")\n",
        "\n",
        "    X = df[APP['final_predictors']].fillna(0)\n",
        "    rf_final = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1, oob_score=True, class_weight='balanced')\n",
        "    rf_final.fit(X, y)\n",
        "    APP['model'] = rf_final\n",
        "\n",
        "    y_probs = rf_final.oob_decision_function_[:, 1] if hasattr(rf_final, \"oob_decision_function_\") else rf_final.predict_proba(X)[:, 1]\n",
        "    m = calculate_advanced_metrics(y, y_probs)\n",
        "    imp = pd.Series(rf_final.feature_importances_, index=APP['final_predictors']).sort_values()\n",
        "\n",
        "    cm = confusion_matrix(y, m['y_pred_opt'])\n",
        "\n",
        "    # --- CALIBRATION PLOT ---\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        subplot_titles=(f\"Feature Importance (Best: {best_days}d)\", \"Confusion Matrix\", \"ROC Curve\"),\n",
        "        vertical_spacing=0.1\n",
        "    )\n",
        "\n",
        "    fig.add_trace(go.Bar(x=imp.values, y=imp.index, orientation='h', marker=dict(color='orange'), name=\"Imp\"), row=1, col=1)\n",
        "\n",
        "    fig.add_trace(go.Heatmap(z=cm, x=['Pred:0', 'Pred:1'], y=['True:0', 'True:1'], colorscale='Blues', showscale=False, text=[[str(y) for y in x] for x in cm], texttemplate=\"%{text}\"), row=2, col=1)\n",
        "    fig.update_yaxes(autorange=\"reversed\", row=2, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=m['fpr'], y=m['tpr'], mode='lines', line=dict(color='royalblue', width=2), fill='tozeroy', name=\"ROC\"), row=3, col=1)\n",
        "    fig.add_trace(go.Scatter(x=[m['fpr'][m['best_idx']]], y=[m['tpr'][m['best_idx']]], mode='markers', marker=dict(color='red', size=12, symbol='star'), name=\"Opt\"), row=3, col=1)\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(color='black', dash='dash'), showlegend=False), row=3, col=1)\n",
        "\n",
        "    fig.update_layout(template=\"plotly_white\", height=900, showlegend=False, margin=dict(l=10, r=10, t=30, b=10))\n",
        "\n",
        "    metrics_html = widgets.HTML(f\"\"\"\n",
        "    <div style=\"color: black; font-family: sans-serif; font-size: 11px; margin: 10px 0; line-height: 1.6;\">\n",
        "        <strong>Selected Rainfall Window:</strong> {best_days} Days<br>\n",
        "        <strong>Training overall accuracy:</strong> {m['acc']:.4f}<br>\n",
        "        <strong>Area under curve:</strong> {m['auc']:.4f}<br>\n",
        "        <strong>Youden Index:</strong> {m['youden']:.4f}<br>\n",
        "        <strong>Cohen's Kappa:</strong> {m['kappa']:.4f}<br>\n",
        "        <strong>F1 Score:</strong> {m['f1']:.4f}\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    df['calib_prob'] = rf_final.predict_proba(X)[:, 1]\n",
        "    df['calib_pred'] = m['y_pred_opt']\n",
        "    df['conf_class'] = df.apply(lambda r: calc_confusion_class(r, 'calib_pred'), axis=1)\n",
        "\n",
        "    # APPLY FILTER BEFORE DOWNLOAD\n",
        "    df_export = filter_dataframe_for_export(df)\n",
        "    download_btn = create_download_link(df_export, \"Download Calibration CSV\", \"calibration.csv\")\n",
        "\n",
        "    show_floating_panel(\n",
        "        widgets.VBox([metrics_html, go.FigureWidget(fig), download_btn], layout=widgets.Layout(align_items='stretch')),\n",
        "        title=\"Calibration Results\",\n",
        "        panel_key='calib'\n",
        "    )\n",
        "\n",
        "    map_values(df, 'calib_prob', 'Calibration Map', VIS_PALETTE)\n",
        "    map_values(df, 'conf_class', 'Confusion Calibration', PALETTE_CONFUSION)\n",
        "\n",
        "def on_valid_click(b):\n",
        "    out_log.clear_output()\n",
        "    with out_log: print(\"Starting Validation process...\")\n",
        "\n",
        "    if APP['model'] is None:\n",
        "        with out_log: print(\"ERROR: You must run Calibration first!\")\n",
        "        return\n",
        "\n",
        "    if 'final_predictors' not in APP or not APP['final_predictors']:\n",
        "        with out_log: print(\"ERROR: Predictors not found. Run Calibration again.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        df = APP['df']\n",
        "        X = df[APP['final_predictors']].fillna(0)\n",
        "        y = df['P/A']\n",
        "\n",
        "        with out_log: print(\"Running Cross-Validation (10-Folds)... please wait.\")\n",
        "        y_probs = cross_val_predict(APP['model'], X, y, cv=StratifiedKFold(n_splits=10, shuffle=True), method='predict_proba', n_jobs=-1)[:, 1]\n",
        "        m = calculate_advanced_metrics(y, y_probs)\n",
        "\n",
        "        cm = confusion_matrix(y, m['y_pred_opt'])\n",
        "\n",
        "        metrics_html = widgets.HTML(f\"\"\"\n",
        "        <div style=\"color: black; font-family: sans-serif; font-size: 11px; margin: 10px 0; line-height: 1.6;\">\n",
        "            <strong>Training overall accuracy:</strong> {m['acc']:.4f}<br>\n",
        "            <strong>Area under curve:</strong> {m['auc']:.4f}<br>\n",
        "            <strong>Youden Index:</strong> {m['youden']:.4f}<br>\n",
        "            <strong>Cohen's Kappa:</strong> {m['kappa']:.4f}<br>\n",
        "            <strong>F1 Score:</strong> {m['f1']:.4f}\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Confusion Matrix\", \"CV ROC Curve\"), vertical_spacing=0.15)\n",
        "\n",
        "        fig.add_trace(go.Heatmap(z=cm, x=['Pred:0', 'Pred:1'], y=['True:0', 'True:1'], colorscale='Blues', showscale=False, text=[[str(y) for y in x] for x in cm], texttemplate=\"%{text}\"), row=1, col=1)\n",
        "        fig.update_yaxes(autorange=\"reversed\", row=1, col=1)\n",
        "\n",
        "        fig.add_trace(go.Scatter(x=m['fpr'], y=m['tpr'], mode='lines', line=dict(color='darkorange', width=2), fill='tozeroy', name=\"ROC\"), row=2, col=1)\n",
        "        fig.add_trace(go.Scatter(x=[m['fpr'][m['best_idx']]], y=[m['tpr'][m['best_idx']]], mode='markers', marker=dict(color='red', size=12, symbol='star'), name=\"Opt\"), row=2, col=1)\n",
        "        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(color='black', dash='dash'), showlegend=False), row=2, col=1)\n",
        "\n",
        "        fig.update_layout(template=\"plotly_white\", height=500, showlegend=False, margin=dict(l=10, r=10, t=30, b=10))\n",
        "\n",
        "        df['valid_prob'] = y_probs\n",
        "        df['valid_pred'] = m['y_pred_opt']\n",
        "        df['valid_conf'] = df.apply(lambda r: calc_confusion_class(r, 'valid_pred'), axis=1)\n",
        "\n",
        "        # APPLY FILTER BEFORE DOWNLOAD\n",
        "        df_export = filter_dataframe_for_export(df)\n",
        "        download_btn = create_download_link(df_export, \"Download Validation CSV\", \"validation.csv\")\n",
        "\n",
        "        show_floating_panel(\n",
        "            widgets.VBox([metrics_html, go.FigureWidget(fig), download_btn], layout=widgets.Layout(align_items='stretch')),\n",
        "            title=\"Validation Results\",\n",
        "            panel_key='valid'\n",
        "        )\n",
        "\n",
        "        map_values(df, 'valid_prob', 'Validation Map', VIS_PALETTE)\n",
        "        map_values(df, 'valid_conf', 'Confusion Validation', PALETTE_CONFUSION)\n",
        "        with out_log: print(\"Validation Done.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        with out_log: print(f\"SYSTEM ERROR: {e}\")\n",
        "\n",
        "def on_pred_click(b):\n",
        "    if APP['model'] is None:\n",
        "        with out_log: print(\"Model missing.\")\n",
        "        return\n",
        "    out_log.clear_output()\n",
        "    best_w = APP['best_window']\n",
        "\n",
        "    try:\n",
        "        df_pred = get_prediction_data_dynamic(best_w, out_log)\n",
        "\n",
        "        X_map = df_pred[APP['final_predictors']].fillna(0)\n",
        "        probs = APP['model'].predict_proba(X_map)[:, 1]\n",
        "        df_pred['SI'] = probs\n",
        "        map_values(df_pred, 'SI', 'Prediction Map', VIS_PALETTE)\n",
        "\n",
        "        risk_html = widgets.HTML(f\"\"\"<div style=\"color: black; font-family: sans-serif; font-size: 14px; margin-bottom: 10px; font-weight: bold; text-align: center;\">Max Risk Score: {probs.max():.2f}</div>\"\"\")\n",
        "\n",
        "        # Prediction CSV already only has 1 rainfall column, but we filter just to be consistent with 'BEST_ONLY' setting\n",
        "        df_export = filter_dataframe_for_export(df_pred)\n",
        "        download_btn = create_download_link(df_export, \"Download Prediction CSV\", \"prediction.csv\")\n",
        "\n",
        "        show_floating_panel(\n",
        "            widgets.VBox([risk_html, download_btn]),\n",
        "            title=\"Prediction\", width='220px', panel_key='pred'\n",
        "        )\n",
        "        with out_log: print(f\"Prediction Done. Max Risk: {probs.max():.2f}\")\n",
        "    except Exception as e:\n",
        "        with out_log: print(f\"Error: {e}\")\n",
        "\n",
        "# --- INIT MAP ---\n",
        "Map = geemap.Map(height='900px', zoom_control=False, draw_control=False, fullscreen_control=True)\n",
        "Map.centerObject(prediction_area_shp, 10)\n",
        "Map.add_control(ZoomControl(position='bottomleft'))\n",
        "try:\n",
        "    if hasattr(Map, 'layer_control'): Map.remove_control(Map.layer_control)\n",
        "except: pass\n",
        "APP['map'] = Map\n",
        "\n",
        "btn_style = widgets.ButtonStyle(button_color='#00BFFF', text_color='#ffffff', font_weight='bold')\n",
        "layout = widgets.Layout(width='180px', margin='2px')\n",
        "b_init = widgets.Button(description=\"Run Analysis\", layout=layout, style=btn_style)\n",
        "b_calib = widgets.Button(description=\"Run Calibration\", layout=layout, style=btn_style)\n",
        "b_valid = widgets.Button(description=\"Run Validation\", layout=layout, style=btn_style)\n",
        "b_pred = widgets.Button(description=\"Run Prediction\", layout=layout, style=btn_style)\n",
        "\n",
        "b_calib.on_click(on_calib_click)\n",
        "b_valid.on_click(on_valid_click)\n",
        "b_pred.on_click(on_pred_click)\n",
        "\n",
        "start_ctrl = WidgetControl(widget=widgets.VBox([b_init], layout=widgets.Layout(padding='5px', background_color='white', border_radius='8px')), position='bottomright')\n",
        "main_ctrl = WidgetControl(widget=widgets.HBox([b_calib, b_valid, b_pred], layout=widgets.Layout(padding='5px', background_color='white', border_radius='8px')), position='bottomright')\n",
        "\n",
        "def activate_analysis(b):\n",
        "    out_log.clear_output()\n",
        "    display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000});'''))\n",
        "\n",
        "    Map.addLayer(predictors_polygons.style(**{'color': 'gray', 'fillColor': '00000000'}), {}, 'Study Area')\n",
        "    try:\n",
        "        Map.remove_control(start_ctrl)\n",
        "        Map.add_control(main_ctrl)\n",
        "        legend_widget = create_legend_widget()\n",
        "        legend_control = WidgetControl(widget=legend_widget, position='bottomleft')\n",
        "        Map.add_control(legend_control)\n",
        "    except Exception as e: print(e)\n",
        "\n",
        "b_init.on_click(activate_analysis)\n",
        "Map.add_control(start_ctrl)\n",
        "\n",
        "display(widgets.VBox([widgets.HTML('<div style=\"font-weight: bold; color: black; font-family: sans-serif;\">OPERATION LOG</div>'), out_log]))\n",
        "display(Map)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}